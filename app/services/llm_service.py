# app/services/llm_service.py

# import openai
# import google.generativeai as genai
from typing import Dict, Any
from app.core.config import settings
from captioning_module.model import image_captioner  # ëª¨ë¸ ë¡œì§ ì¬ì‚¬ìš©
import time  # í† í° ì‚¬ìš©ëŸ‰ ê³„ì‚° ë° ì¶œë ¥ì„ ìœ„í•´ ì‚¬ìš©
from openai import AsyncOpenAI  # AsyncOpenAIë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
import json  # JSON ì‘ë‹µ íŒŒì‹±ì„ ìœ„í•´ ì‚¬ìš©

if settings.CHATGPT_API_KEY:
    async_openai_client = AsyncOpenAI(api_key=settings.CHATGPT_API_KEY)
else:
    async_openai_client = None


# --- í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜ (ê¸°ì¡´ ë¡œì§ ìœ ì§€) ---
def set_prompt(original_caption: str, file_info: str) -> str:
    """LLMì— ì „ë‹¬í•  ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    return (
        f"ë‹¹ì‹ ì€ ì‹œê° ì¥ì• ì¸ ì¹œêµ¬ì—ê²Œ ì‚¬ì§„ì„ ì„¤ëª…í•´ì£¼ëŠ” ë‹¤ì •í•˜ê³  ì¹œê·¼í•œ ì¹œêµ¬ì…ë‹ˆë‹¤.\n"
        f"ì´ ì‚¬ì§„ì˜ ì›ë˜ ìº¡ì…˜ì€ '{original_caption}'ì…ë‹ˆë‹¤.\n"
        f"ì¹œêµ¬ì˜ ì¶”ê°€ ì„¤ëª…ì€ '{file_info}'ì…ë‹ˆë‹¤.\n"
        f"ì´ ë‘ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì¹œêµ¬ê°€ ëˆˆìœ¼ë¡œ ë³´ëŠ” ê²ƒì²˜ëŸ¼ ì‚¬ì§„ì˜ ìƒí™©, ë¶„ìœ„ê¸°, ê·¸ë¦¬ê³  ëŠê»´ì§€ëŠ” ê°ì •ë“¤ì„ ìƒìƒí•˜ê³  ì§ê´€ì ì¸ ì–¸ì–´ë¡œ ì „ë‹¬í•´ì£¼ì„¸ìš”."
    )


def set_test_prompt(original_caption: str, file_info: str) -> str:
    """ChatGPTìš© ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ ì¡°í•©)"""
    return f"""Photo description: {original_caption},
            Additional info: {file_info}"""


# --- í† í° ì‚¬ìš©ëŸ‰ ì²´í¬ ë¡œì§ (Persistence ì œê±°, Limit ì²´í¬ëŠ” ìœ ì§€) ---
def get_estimated_tokens(text: str, is_korean: bool = True) -> int:
    """í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë”°ë¼ í† í°ì„ ì¶”ì •í•©ë‹ˆë‹¤."""
    # í•œêµ­ì–´ëŠ” ë¬¸ìë‹¹ í† í° ë¹„ìœ¨ì´ ë†’ìŒ (ì•½ 1.5~2ë°°)
    ratio = 2 if is_korean else 1.2
    return int(len(text.split()) * ratio)


# **ì°¸ê³ **: í† í° ì‚¬ìš©ëŸ‰ì˜ DB ì˜ì†ì„±(ì €ì¥)ì´ ì œê±°ë˜ì—ˆìœ¼ë¯€ë¡œ,
# ì¼ì¼ ì œí•œ(DAILY_TOKEN_LIMIT) ì²´í¬ëŠ” 'í˜„ì¬ í˜¸ì¶œì˜ ì˜ˆìƒ ë¹„ìš©'ë§Œ ì²´í¬í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë‹¨ìˆœí™”ë©ë‹ˆë‹¤.
# ì‹¤ì œ ë°°í¬ ì‹œì—ëŠ” Redis ë“±ìœ¼ë¡œ ì¼ì¼ ì‚¬ìš©ëŸ‰ì„ ë‹¤ì‹œ ê´€ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.


# # --- LLM ì—°ë™ ë° ìº¡ì…˜ ìƒì„± í•¨ìˆ˜ (Gemini) ---
# async def get_refined_caption_with_gemini_async(original_caption: str, file_info: str):
#     if not settings.GEMINI_API_KEY:
#         return "LLM API í˜¸ì¶œ ì‹¤íŒ¨: Gemini API key is not configured."

#     prompt = set_prompt(original_caption, file_info)

#     # í† í° ì‚¬ìš©ëŸ‰ ì²´í¬ (í˜„ì¬ í˜¸ì¶œì˜ ì˜ˆìƒ ë¹„ìš©ë§Œ í™•ì¸)
#     estimated_input_tokens = get_estimated_tokens(prompt)
#     if estimated_input_tokens * 2 >= settings.DAILY_TOKEN_LIMIT:
#         return "ì¼ì¼ í† í° ì‚¬ìš©ëŸ‰ ì œí•œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. (ë‹¨ì¼ ìš”ì²­ í¬ê¸° ì´ˆê³¼)"

#     try:
#         # NOTE: genai.GenerativeModel.generate_contentëŠ” ë™ê¸° í•¨ìˆ˜ì…ë‹ˆë‹¤.
#         # FastAPIì—ì„œ ë™ê¸° í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ë©´ ë‹¤ë¥¸ ìš”ì²­ì„ ë¸”ë¡œí‚¹í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ,
#         # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” run_in_threadpool ë“±ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
#         # ì—¬ê¸°ì„œëŠ” ë¡œì§ í¬íŒ…ì„ ìœ„í•´ ë™ê¸° í˜¸ì¶œë¡œ ë‘¡ë‹ˆë‹¤.
#         model = genai.GenerativeModel("gemini-1.5-flash")
#         response = model.generate_content(prompt)
#         refined_caption = response.text

#         # í† í° ì‚¬ìš©ëŸ‰ ì‹œë®¬ë ˆì´ì…˜ ì¶œë ¥ (PersistenceëŠ” ì—†ìŒ)
#         output_tokens = get_estimated_tokens(refined_caption)
#         print(
#             f"[Gemini] ì˜ˆìƒ í† í° ì‚¬ìš©ëŸ‰ (ì…ë ¥/ì¶œë ¥): {estimated_input_tokens}/{output_tokens}. (Limit: {settings.DAILY_TOKEN_LIMIT})"
#         )

#         return refined_caption
#     except Exception as e:
#         print(f"Error calling Gemini API: {e}")
#         return f"LLM API í˜¸ì¶œ ì‹¤íŒ¨: {e}"


# --- í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜ ìˆ˜ì • ---
def set_prompt_for_keyword(original_caption: str, file_info: str) -> str:
    """LLMì— ì „ë‹¬í•  ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ë° í‚¤ì›Œë“œ ì¶”ì¶œ ì§€ì‹œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    return (
        f"ë‹¹ì‹ ì€ ì‹œê° ì¥ì• ì¸ ì¹œêµ¬ì—ê²Œ ì‚¬ì§„ì„ ì„¤ëª…í•´ì£¼ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤.\n"
        f"ì´ ì‚¬ì§„ì˜ ì›ë˜ ìº¡ì…˜ì€ '{original_caption}'ì…ë‹ˆë‹¤.\n"
        f"ì‚¬ìš©ìì˜ ì¶”ê°€ ì„¤ëª…ì€ '{file_info}'ì…ë‹ˆë‹¤.\n"
        f"ì´ ë‘ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë‹¤ìŒ ë‘ ê°€ì§€ë¥¼ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.\n\n"
        # 1. ìµœì¢… í•´ì„¤ ìƒì„± ì§€ì‹œ
        f"A. ëˆˆìœ¼ë¡œ ë³´ëŠ” ê²ƒì²˜ëŸ¼ ì‚¬ì§„ì˜ ìƒí™©, ë¶„ìœ„ê¸°, ê·¸ë¦¬ê³  ëŠê»´ì§€ëŠ” ê°ì •ë“¤ì„ ìƒìƒí•˜ê³  ì§ê´€ì ì¸ ì–¸ì–´ë¡œ ì „ë‹¬í•˜ëŠ” ìµœì¢… í•´ì„¤ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\n"
        # 2. í‚¤ì›Œë“œ ì¶”ì¶œ ì§€ì‹œ (ê°€ì¥ ì¤‘ìš”í•œ ë¶€ë¶„)
        f"B. ì´ ì‚¬ì§„ê³¼ í•´ì„¤ì„ ëŒ€í‘œí•˜ëŠ” **ê°ì²´, ì¥ì†Œ, ë¶„ìœ„ê¸°, ê°ì •**ì„ í¬í•¨í•˜ëŠ” **10ê°œì˜ í•µì‹¬ í‚¤ì›Œë“œ**ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”. í‚¤ì›Œë“œëŠ” ëª…ì‚¬ ë˜ëŠ” ëª…ì‚¬êµ¬ í˜•íƒœì—¬ì•¼ í•˜ë©°, 'ê°•ì•„ì§€', 'í•´ë³€', 'ë”°ëœ»í•¨'ê³¼ ê°™ì´ ëª…í™•í•´ì•¼ í•©ë‹ˆë‹¤."
    )


async def get_refined_caption_and_keywords_with_chatgpt_async(
    original_caption: str, file_info: str
) -> Dict[str, Any]:  # ì‘ë‹µ íƒ€ì…ì„ Dictë¡œ ë³€ê²½
    """
    ChatGPT APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìº¡ì…˜ ê°œì„  ë° 10ê°œ í‚¤ì›Œë“œë¥¼ JSONìœ¼ë¡œ ë°›ì•„ íŒŒì‹±í•©ë‹ˆë‹¤.
    """
    if not async_openai_client:
        # í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë„ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜
        return {
            "refined_caption": "LLM API í˜¸ì¶œ ì‹¤íŒ¨: ChatGPT API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "keywords": [],
        }

    # --- 1. JSON ì‘ë‹µì„ ìœ„í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜ (í‚¤ì›Œë“œ í•­ëª© ì¶”ê°€) ---
    system_prompt = (
        "You are a helpful assistant that refines an image caption based on provided context. "
        "Your final response MUST be a single JSON object with two keys: 'refined_caption' (String) and 'keywords' (Array of Strings). "
        "The value of 'refined_caption' should be the final, refined caption in Korean. "
        "The value of 'keywords' MUST be an array containing exactly 10 keywords in Korean."
    )

    # --- 2. ì‚¬ìš©ì ì…ë ¥ í”„ë¡¬í”„íŠ¸ ìƒì„± (ìƒˆë¡œìš´ í•¨ìˆ˜ ì‚¬ìš©) ---
    prompt = set_prompt_for_keyword(original_caption, file_info)
    model_name = "gpt-3.5-turbo"  # ì‚¬ìš©í•  ëª¨ë¸

    try:
        completion = await async_openai_client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt},
            ],
            temperature=0.7,
            response_format={"type": "json_object"},  # JSON í˜•ì‹ ìš”ì²­
        )

        # 3. ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° íŒŒì‹±
        response_text = completion.choices[0].message.content
        data = json.loads(response_text)

        # 4. í‚¤ì™€ ìº¡ì…˜ ì¶”ì¶œ
        refined_caption = data.get("refined_caption", "ìº¡ì…˜ ìƒì„± ê²°ê³¼ ì—†ìŒ")
        keywords = data.get("keywords", [])  # í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ

        # ìµœì¢… ë°˜í™˜: ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ìº¡ì…˜ê³¼ í‚¤ì›Œë“œ ëª¨ë‘ ë°˜í™˜
        return {"refined_caption": refined_caption, "keywords": keywords}

    except Exception as e:
        print(f"Error calling ChatGPT API: {e}")
        return {"refined_caption": f"LLM API í˜¸ì¶œ ì‹¤íŒ¨: {e}", "keywords": []}


# ğŸŒŸ ì „ì—­ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜, ì„¤ì •ë˜ì§€ ì•Šì•˜ë‹¤ë©´ Noneì„ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •
async def translate_to_korean_async(english_text: str) -> str:
    """
    GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ì–´ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤.
    (ê²½ëŸ‰ í”„ë¡¬í”„íŠ¸ë¡œ í† í° ì‚¬ìš© ìµœì†Œí™”)
    """
    # ğŸŒŸ ì „ì—­ìœ¼ë¡œ ìƒì„±ëœ í´ë¼ì´ì–¸íŠ¸(async_openai_client)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    client = async_openai_client 

    if not client:
        # LLM í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ë²ˆì—­ ë¶ˆê°€ëŠ¥
        print("LLM Translation skipped: ChatGPT API key is not configured.")
        return english_text
        
    system_prompt = "You are a professional Korean translator. Translate the given text into natural Korean. Do not add any explanations or extra text."

    try:
        response = await client.chat.completions.create( # client(ì „ì—­) ì‚¬ìš©
            model="gpt-3.5-turbo",  
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": english_text},
            ],
            temperature=0.1, 
            max_tokens=200,  
        )
        return response.choices[0].message.content.strip()

    except Exception as e:
        print(f"LLM Translation failed: {e}")
        return english_text